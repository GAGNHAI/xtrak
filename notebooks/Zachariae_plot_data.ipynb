{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "data_dir='ATL06/ATL06'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "# make sure we're dealing with the most recent version of any code we're using\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Analysis of clouds over outlet glaciers</font> <br>\n",
    "Plot of ATL06 tracks after file transfers using aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "def ATL06_to_dict(filename, dataset_dict):\n",
    "    \"\"\"\n",
    "        Read selected datasets from an ATL06 file\n",
    "\n",
    "        Input arguments:\n",
    "            filename: ATl06 file to read\n",
    "            dataset_dict: A dictinary describing the fields to be read\n",
    "                    keys give the group names to be read, \n",
    "                    entries are lists of datasets within the groups\n",
    "        Output argument:\n",
    "            D6: dictionary containing ATL06 data.  Each dataset in \n",
    "                dataset_dict has its own entry in D6.  Each dataset \n",
    "                in D6 contains a list of numpy arrays containing the \n",
    "                data\n",
    "    \"\"\"\n",
    "    \n",
    "    D6=[]\n",
    "    pairs=[1, 2, 3]\n",
    "    beams=['l','r']\n",
    "    # open the HDF5 file\n",
    "    with h5py.File(filename) as h5f:\n",
    "        # loop over beam pairs\n",
    "        for pair in pairs:\n",
    "            # loop over beams\n",
    "            for beam_ind, beam in enumerate(beams):\n",
    "                # check if a beam exists, if not, skip it\n",
    "                if '/gt%d%s/land_ice_segments' % (pair, beam) not in h5f:\n",
    "                    continue\n",
    "                # loop over the groups in the dataset dictionary\n",
    "                temp={}\n",
    "                for group in dataset_dict.keys():\n",
    "                    for dataset in dataset_dict[group]:\n",
    "                        DS='/gt%d%s/%s/%s' % (pair, beam, group, dataset)\n",
    "                        # since a dataset may not exist in a file, we're going to try to read it, and if it doesn't work, we'll move on to the next:\n",
    "                        try:\n",
    "                            temp[dataset]=np.array(h5f[DS])\n",
    "                            # some parameters have a _FillValue attribute.  If it exists, use it to identify bad values, and set them to np.NaN\n",
    "                            if '_FillValue' in h5f[DS].attrs:\n",
    "                                fill_value=h5f[DS].attrs['_FillValue']\n",
    "                                temp[dataset][temp[dataset]==fill_value]=np.NaN\n",
    "                        except KeyError as e:\n",
    "                            pass\n",
    "                if len(temp) > 0:\n",
    "                    # it's sometimes convenient to have the beam and the pair as part of the output data structure: This is how we put them there.\n",
    "                    temp['pair']=np.zeros_like(temp['h_li'])+pair\n",
    "                    temp['beam']=np.zeros_like(temp['h_li'])+beam_ind\n",
    "                    temp['filename']=filename\n",
    "                    D6.append(temp)\n",
    "    return D6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict={'land_ice_segments':['h_li', 'delta_time','longitude','latitude'], 'land_ice_segments/ground_track':['x_atc']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =\"5\"> Interpolation and Filtering</font> <br>\n",
    "From the analysis of individual tracks, there are several NaNs or missing values from each ICESat2 tracks. There are several steps from which we try to fix the NaNs and smooth the elevation data. First, we interpolate the NaNs from the dataframe using Pandas. Then, we use a median filter with 1$\\sigma$ and window size to extrapolate or smoothen the time series. This is essestial to compare the filtered ICESat2 tracks with ATM tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 54 beam/pair combinations\n",
      "dict_keys(['land_ice_segments', 'land_ice_segments/ground_track'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f89be011ef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: From now on, we'll be working in matplotlib's widget mode, which lets us zoom in on our plots.  \n",
    "# This means that the figures won't be rendered in the notebook until you run them.\n",
    "# That means no more spoiler plots (for now...)\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "data_dir='/home/jovyan/ATL06_data/ATL06/'\n",
    "D6=[]\n",
    "pairs=[1, 2, 3]\n",
    "beams=['l','r']\n",
    "\n",
    "files=glob(data_dir+'/*.h5')\n",
    "for file in files:\n",
    "    this_name=os.path.basename(file)\n",
    "    D6 += ATL06_to_dict(file, dataset_dict)\n",
    "print(\"read %d beam/pair combinations\" % (len(D6)))\n",
    "print(dataset_dict.keys())\n",
    "# now plot the results:\n",
    "plt.figure();\n",
    "for Di in D6:\n",
    "    plt.scatter(Di['longitude'], Di['latitude'], c=Di['h_li'], vmin=0, vmax=2000, linewidth=0)\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/jovyan/ATL06_data/ATL06/processed_ATL06_20181206134817_10530103_001_01.h5', '/home/jovyan/ATL06_data/ATL06/processed_ATL06_20181206025850_10460105_001_01.h5', '/home/jovyan/ATL06_data/ATL06/processed_ATL06_20181128140455_09310103_001_01.h5', '/home/jovyan/ATL06_data/ATL06/processed_ATL06_20181222022533_12900105_001_01.h5', '/home/jovyan/ATL06_data/ATL06/processed_ATL06_20181214133137_11750103_001_01.h5']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8042eb426234bc68245e3ccc04b8ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    7121\n",
      "col2    7107\n",
      "dtype: int64\n",
      "col1    7121\n",
      "col2    7121\n",
      "dtype: int64\n",
      "col1      7121\n",
      "col2      7121\n",
      "median    6996\n",
      "std       6996\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c683c55377431ca3fc2caf743f7494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1      7121\n",
      "col2      7121\n",
      "median    6996\n",
      "std       6996\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ae0491e66948448545224472845f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    5971\n",
      "col2    5954\n",
      "dtype: int64\n",
      "col1    5971\n",
      "col2    5971\n",
      "dtype: int64\n",
      "col1      5971\n",
      "col2      5971\n",
      "median    5851\n",
      "std       5851\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad7c205437945ec83d27dc984c64258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1      5971\n",
      "col2      5971\n",
      "median    5851\n",
      "std       5851\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5221ca23e8f4f7c84ad4799c015fbd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    6832\n",
      "col2    6809\n",
      "dtype: int64\n",
      "col1    6832\n",
      "col2    6832\n",
      "dtype: int64\n",
      "col1      6832\n",
      "col2      6832\n",
      "median    6712\n",
      "std       6712\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9500521ba9a44314ab3eba44ed5eb4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1      6832\n",
      "col2      6832\n",
      "median    6712\n",
      "std       6712\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d77fd84505fa4bb1b79e52856d541edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    6460\n",
      "col2    6441\n",
      "dtype: int64\n",
      "col1    6460\n",
      "col2    6459\n",
      "dtype: int64\n",
      "col1      6460\n",
      "col2      6459\n",
      "median    6283\n",
      "std       6283\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678cf16af9854b9eba40b84d5f3c0b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1      6460\n",
      "col2      6459\n",
      "median    6283\n",
      "std       6283\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee4bf4542a24e928956de361ffacea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1    4124\n",
      "col2    4124\n",
      "dtype: int64\n",
      "col1    4124\n",
      "col2    4124\n",
      "dtype: int64\n",
      "col1      4124\n",
      "col2      4124\n",
      "median    3987\n",
      "std       3987\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445ae67a50494f4ab5713f9479a83006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1      4124\n",
      "col2      4124\n",
      "median    3987\n",
      "std       3987\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset_dict={'land_ice_segments':['latitude','longitude','h_li'], 'land_ice_segments/ground_track':['x_atc']}\n",
    "print(files[0:5])\n",
    "%matplotlib widget\n",
    "for file in files[0:5]:\n",
    "    this_D6=ATL06_to_dict(file, dataset_dict)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    initial_plot = plt.plot(this_D6[1]['x_atc'], this_D6[1]['h_li'],'.')\n",
    "    plt.title(this_D6[1]['filename'])\n",
    "    \n",
    "    a = this_D6[1]['x_atc'];\n",
    "    b = this_D6[1]['h_li'];\n",
    "    d = {'col1':a,'col2':b}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    NaN_count = df.count()\n",
    "    print(NaN_count)\n",
    "    #print(df)\n",
    "    #df_median = df.rolling(21).median()\n",
    "    #x = df.plot(x='col1',y='col2')\n",
    "    #df_median.plot(x='col1',y='col2',ax = x,figsize=(5,4))\n",
    "    \n",
    "    # Interpolate the missing NaN in the track\n",
    "    df1 = df.interpolate(method ='linear', limit_direction ='forward') \n",
    "    NaN_count1 = df1.count()\n",
    "    print(NaN_count1)\n",
    "    #df1.plot(x='col1',y='col2',figsize=(5,4))\n",
    "    \n",
    "    #Filtering\n",
    "    window = 121\n",
    "    df1['median']= df1['col2'].rolling(window).median()\n",
    "    df1['std'] = df1['col2'].rolling(window).std()\n",
    "\n",
    "    #filter setup\n",
    "    df1[(df1.col2 > df1['median']+1*df1['std']) | (df1.col2 < df1['median']-1*df1['std'])] = np.NaN\n",
    "    \n",
    "    df2 = df1.interpolate(method ='linear', limit_direction ='forward') \n",
    "    NaN_count3 = df2.count()\n",
    "    print(NaN_count3)\n",
    "    #df1.plot(x='col1',y='col2',figsize=(5,4))\n",
    "    \n",
    "    x1 = df.plot(x='col1',y='col2',figsize=(5,4))\n",
    "    df2.plot(x='col1',y='col2',figsize=(5,4),ax=x1)\n",
    "    NaN_count2 = df2.count()\n",
    "    print(NaN_count2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Code to read the data from Evan's folder</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: From now on, we'll be working in matplotlib's widget mode, which lets us zoom in on our plots.  \n",
    "# This means that the figures won't be rendered in the notebook until you run them.\n",
    "# That means no more spoiler plots (for now...)\n",
    "%matplotlib widget\n",
    "\n",
    "\n",
    "data_dir='/home/jovyan/xtrak/data/'\n",
    "D6=[]\n",
    "pairs=[1, 2, 3]\n",
    "beams=['l','r']\n",
    "\n",
    "files=glob(data_dir+'/*.h5')\n",
    "for file in files:\n",
    "    this_name=os.path.basename(file)\n",
    "    D6 += ATL06_to_dict(file, dataset_dict)\n",
    "print(\"read %d beam/pair combinations\" % (len(D6)))\n",
    "\n",
    "# now plot the results:\n",
    "plt.figure();\n",
    "for Di in D6:\n",
    "    plt.scatter(Di['longitude'], Di['latitude'], c=Di['h_li'], vmin=0, vmax=2000, linewidth=0)\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets look at few granules from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict={'land_ice_segments':['latitude','longitude','h_li'], 'land_ice_segments/ground_track':['x_atc']}\n",
    "\n",
    "%matplotlib widget\n",
    "for file in files[9:15]:\n",
    "    this_D6=ATL06_to_dict(file, dataset_dict)\n",
    "    plt.figure()\n",
    "    plt.plot(this_D6[1]['x_atc'], this_D6[1]['h_li'],'.')\n",
    "    plt.title(this_D6[1]['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
